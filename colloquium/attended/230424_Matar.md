# MATAR: A performance portability productivity implementation of data-oriented design with Kokkos
Paper by  
Presentation by Luuk de Graaf  
Summary by Simon van Hus (6147879)

---

- Cache and prefetching to speed up
- Use in a contiguous matter:
    - Data structures
    - Vectorization
- GPU
- Array of structs < Structs of arrays (Object Oriented vs Data Oriented)
- 2D array:
    - NaÃ¯ve allocation results in second dimension's arrays in random location in memory
- Ragged data structures
    - Static: single array with pointers to the start of each sub-array
    - Dynamic: single array with buffer room and pointers to the start and end of each sub-array
    - Linked lists are not cache friendly either (many pointers (with costly reallocation), often not contiguous (with reallocating would defeat the purpose))
- Compressed sparse matrix
    - Store all non-zero values in a values array, and for each value store the row and column in row_indices and column_indices arrays
- Views
    - Interpretation of an array
    - No performance costs
    - Allows for introduction of non-MATAR data structures

- Focussed on profiling, but cache profiling is pretty hard

- Results:
    - Arrays:
        - Traditial arrays are very similar
        - `CArray` (and views) are much faster, about 40%
        - Not very surprising
    - Matrix multiplication:
        - Traditional arrays actually faster than `CArray`s, not conclusive but problem with accessing
        - Much faster when the second matrix is accessed with column-major accessing
    - Ragged data structures:
        - MATAR again generally slower, more misses in the cache
    - GPU not profiled, glossed over
    - Data-oriented design is faster, but only if you really care about performance
    - Implementations break automatic vectorization, but authors are unsure why (hard to debug)