\section{Background}
    \subsection{Automatic Differentiation} \label{sec:bg_ad}
        Automatic Differentiation (AD), like the name suggests, involves programmatically finding the derivative of some programmed function \cite{margossian2019review}.
        The other main method for programmatically finding the derivative of a function is numerical differentiation, which uses the finite difference method.
        By adjusting the input(s) to the function by a very small number, we can see the effect on the output(s) of the function.
        Unfortunately, due to the way real numbers are represented using floating-point computation, this method is prone to round-off error (or truncation error).
        AD avoids this by actually performing the differentiation on a program, to produce the differentiated program.
        This is very similar to how a human would differentiate a mathematical function (sometimes called symbolic or manual differentiation), but performed on a computer program.
        
        AD makes very explicit use of the chain rule of partial derivatives of compound functions, which provides a method for finding the derivative of compound functions and states that we can combine partial derivatives of parts of the function together into the complete derivative.
        Say we have some single-variate function $h(x)$, which is the compound function of the functions $f$ and $g$:
        \[h(x)=(f\circ g)(x)\]
        In this case, the chain rule tells us that the derivative of $h(x)$ is given by as $\tfrac{d}{dx}h(x)$:
        \[\frac{d}{dx}h(x)=\frac{d}{dx}(f\circ g)(x)=\frac{df}{dg}\biggr|_{g(x)}\cdot\frac{dg}{dx}\biggr|_x\]
        For clarity, in Lagrange's notation, where $h'(x)$ is the derivative of $h(x)$, this same statement can be expressed as:
        \[h'(x)=(f\circ g)'(x)=f'(g(x))\cdot g'(x)\]
        The chain rule also extends to compositions of more than two functions.
        For example, say we have a function $k(x)$ as below:
        \[k(x)=(f\circ g\circ h)(x)\]
        We can then find the find the derivative of $k(x)$ using the chain rule as well:
        \[\frac{d}{dx}k(x)=\frac{d}{dx}(f\circ g\circ h)(x)=\frac{df}{dg}\biggr|_{g(h(x))}\cdot\frac{dg}{dh}\biggr|_{h(x)}\cdot\frac{dh}{dx}\biggr|_x\]
        Again for clarity, in Lagrange's notation this would be:
        \begin{align*}
            k'(x)=(f\circ g\circ h)'(x)&=f'((g\circ h)(x))\cdot(g\circ h)'(x)\\
            &=f'((g\circ h)(x))\cdot g'(h(x))\cdot h'(x)
        \end{align*}

        The chain rule also provides us with a method of deriving multivariate functions.
        For instance, we can imagine a function $f(x,y)$.
        Now, the derivative of $f$ changes depending on which variable we wish to derive with respect to.
        Furthermore this is not a composition of functions, so the chain rule does not come into play.
        However, if we image the variables $x$ and $y$ as single-variable functions $x(t)$ and $y(t)$ we can find the derivative of $f$ with respect to $t$ using the chain rule.
        We get:
        \[f(x(t),y(t))\]
        Now to calculate the derivate of $f$ with respect to $t$, we first need to find the derivative of $x$ with respect to $t$ and the derivative of $y$ with respect to $t$.
        The chain rule tells us that the derivative of $f$ here is equal to the partial derivative of $f$ with respect to $x$ summed with the partial derivative of $f$ with respect to $y$.
        We can express this as:
        \[\frac{d}{dt}f(x(t),y(t))=\frac{\partial f}{\partial x}\biggr|_{x(t)}\cdot\frac{dx}{dt}\biggr|_t+\frac{\partial f}{\partial y}\biggr|_{y(t)}\cdot\frac{dy}{dt}\biggr|_t\]

        An important thing to note about the chain rule is that we still need the intermediate primal values in a compound function.
        Review the following compound function:
        \[(f\circ g\circ h\circ k)(x)\]
        In Lagrange's notation, the derivative becomes:
        \begin{align*}
            (f\circ g\circ h\circ k)'(x)&=f'((g\circ h\circ k)(x))\cdot g'((h\circ k)(x))\cdot h'(k(x))\cdot k'(x)\\
            &=f'({\color{green}g({\color{red}h({\color{blue}k(x)})})})\cdot g'({\color{red}h({\color{blue}k(x)})})\cdot h'({\color{blue}k(x)})\cdot k'(x)
        \end{align*}
        See how on the second line we have highlighted the primal parts of the equation, the intermediate values that we need for finding the derivative.
        Also note how values deeper in the chain are used multiple times; $h(k(x))$ is used twice: first in the derivative $f'$ and second in the derivative $g'$.
        $k(x)$ is even used three times.
        Looking at this example, it becomes very clear that it would be more efficient to calculate $k(x)$ once and save that result somehow, rather than recalculating it every time it came up.
        The storing and reusing of intermediate values is a fundamental property of AD, and is called ``sharing''.

        To actually implement automatic differentiation, we seek to break the target program down to its most basic mathematical operations, for which we know the derivatives.
        Then we can use the chain rule to combine them together into the derivative of the whole program.
        There are two main ways to actually resolve these derivatives: using either forward accumulation or backward/reverse accumulation.
        When applied in AD implementations these are commonly respectively referred to as forward-mode and reverse-mode.
        Both methods are described in the 1986 paper ``The arithmetic of differentiation'' by B. Rall \cite{rall1986arithmetic}.
        
        In forward-mode AD we move through the program to differentiate in normal execution order.
        By knowing which input variable we wish to differentiate, we can compute every step of the derivative as our inputs are used by the program.
        Rall demonstrates this using a method known as dual-numbers, where each real number is represented by a pair of numbers, similar to complex numbers.
        In dual-numbers, the first number in the pair represents the primal part of the number, whereas the second number represents the derivative part (called the tangent in forward-mode).
        When we compute with these numbers through arithmetic operations, we can operate on the primal parts as normal, and use derivative rules to calculate the derivative of the result using the tangent parts.
        An example of this is given in Equation \ref{eq:dualnumbers}, where $\dot{a}$ is the tangent part of some real number $a$.
        \begin{equation} \label{eq:dualnumbers}
            (a,\dot{a})\cdot(b,\dot{b})=(a\cdot b, \dot{a}\cdot b+\dot{b}\cdot a)
        \end{equation}
        Now we can find the derivative of some program with regards to the input $x_i$ by setting $\dot{x_i}$ to $1$, setting the tangents of all other inputs to $0$, and just running through the program calculating tangents as we go.
        The tangent part of the output value(s) is also the calculated derivative of the whole program.

        While forward-mode AD is fairly straightforward, it comes with some drawbacks.
        The main one being that for a function $f:\mathbb{R}^n\to\mathbb{R}^m$ with $n$ inputs and $m$ outputs, to get the effect of each input variable on each output variable, we would need to perform $n$ passes over the function, one for each input variable (or we need to track $n$ tangent parts for each step).
        This is can be cumbersome, especially if $n$ is much larger than $m$.
        For those cases, we might be better off with reverse accumulation, or reverse-mode.

        In reverse-mode, we peg the derivative part of one of our outputs with some seed (often $1$), and set the derivative parts of the other outputs to $0$.
        These derivative parts are generally referred to as adjoints instead of tangents in reverse-mode.
        When the outputs are set, we can work our way back through the function, calculating the derivative parts from the output to the input.
        Intuitively, this computes the gradient of the output dimension we pegged to $1$, or the direction of the steepest slope.
        Practically, the idea of working back through a program requires some way of knowing where the outputs came from (a sort of dependency structure).
        This then requires a forward pass, to find this structure, to calculate the intermediate values, and often to setup any dual-numbers or other implementation details.
        And while reverse-mode is definitely harder to implement, it also provides us with a way to calculate the sensitivity of all inputs to an output, which is much more efficient for functions with many more inputs than outputs (which can be quite common in certain applications like neural networks).

        In mathematical terms, calculating the partial derivative of one output with regards to one input, means calculating one cell in the Jacobian, the matrix of all partial derivatives.
        For a function $f:\mathbb{R}^n\to\mathbb{R}^m$ with $n$ inputs and $m$ outputs, the Jacobian $J_f$ would be a $n\times m$ matrix.
        Here a column $i$ represents the partial derivatives $\tfrac{\partial\vec{f}}{\partial x_i}$, where $\vec{f}$ are all outputs of $f$, and $x_i$ represents a single input.
        A row $j$ then represents the derivatives $\nabla f_j=\tfrac{\partial f_j}{\partial\vec{x}}$, where $\vec{x}$ are all inputs of $f$, and $\nabla f_j$ is also known as the gradient of the single output value $f_j$.
        This is also shown in Equation \ref{eq:jacobian}, showing the Jacobian for some function $f$ with $n$ inputs ($x_1,\dots,x_n$) and $m$ inputs ($f_1,\dots,f_m$).
        An important take-away here is that forward-mode computes the derivatives of all outputs with regards to a single input, so a column in the Jacobian, and reverse-mode computes the derivatives of all inputs with regards to a single output, so a row in the Jacobian.
        Again, if we want to calculate the full Jacobian, forward-mode is more efficient when we have more outputs than inputs or when the Jacobian has more columns than rows, and the reverse-mode is more efficient for functions with more inputs than outputs or for Jacobians with more rows than columns.

        \begin{equation} \label{eq:jacobian}
            J_f=\left[\frac{\partial \vec{f}}{\partial x_1},\dots,\frac{\partial \vec{f}}{\partial x_n}\right]=\begin{bmatrix}\nabla f_1\\\vdots\\\nabla f_m\end{bmatrix}=\begin{bmatrix}
                \frac{\partial f_1}{\partial x_1} & \dots & \frac{\partial f_1}{\partial x_n}\\
                \vdots & \ddots & \vdots\\
                \frac{\partial f_m}{\partial x_1} & \dots & \frac{\partial f_m}{\partial x_n}
            \end{bmatrix}
        \end{equation}

        While it has long been known that reverse-mode automatic differentiation could be executed in time equal to some constant multiple of the execution time of the primal program \cite{linnainmaa1976taylor}, it seemed that a constant multiple of the execution memory was also needed, which could become very expensive for large programs.
        However, in 1992, Andreas Griewank showed that by using taping and checkpointing we could trace time complexity for space complexity to reduce either to a constant multiple of the log of the execution time \cite{griewank1992achieving}.
        In general the practice of taping refers to a form of tracing on the program we wish to differentiate, where we execute the program as normal and record all the steps and intermediate values in a first-in-last-out data structure referred to as a ``tape'' or Wengert list.
        In a second phase to the reverse-mode algorithm, the tape is then used to calculate the derivatives in question, which due to the first-in-last-out nature of the tape, is in the precise reverse of the execution order of the program.
        An important advantage of taping is that by giving each variable and intermediate calculation a unique id we can avoid redundant execution, because we can just refer to the intermediate value or tangent/adjoint stored in the tape.
        While taping is efficient time-wise, it clearly adds a memory overhead that can be quite sizable for large programs.
        Checkpointing aims to address this by storing multiple parts of the tape to memory attached to checkpoints in the program's execution.
        The trick here being, that on the reverse-pass only the intermediate values from the most recently encountered checkpoint are loaded from memory, intermediate values that were not stored as part of this checkpoint are recalculated.
        By strategically placing these checkpoints, and deciding which intermediate values are stored, this can cut the size complexity at a relatively small time complexity increase.
        It should be noted that automatic differentiation can also be performed on a program where we do not have any specific inputs.
        We can do this using source transformation \cite{bischof2000computing}.
        In its most basic form source transformation can be implemented as just interlacing the derivative calculations into the regular program.
        An example of this is provided in Listing \ref{lst:transformation_fw}, where we calculate the derivative of some variable y (as dy) with regards to the variable x1.
        For reverse-mode AD this kind of interlacing is not possible, as we need to reach the end of the program before we can start the reverse pass, which is exactly why we record our steps on the tape: so we can reverse over the tape and know how to produce our reverse AD program.
        An example of this is provided in Listing \ref{lst:transformation_rv}, where we again calculate the derivative of y (as dy), with regards to x1 and x2.
        So, to summarize, for a function $f:A\to B$, source transformation finds the derivative function for any input in the domain $A$, whereas dual-numbers (or similar approaches) find the derivative function for a specific input $a\in A$.
        Of course, in complex functions with a lot of control flow, source transformation can become cumbersome as it needs to account for all possible inputs, whereas dual-numbers only needs to account for one.

        \begin{quicklst}[caption={An example of forward mode AD by source transformation, with the AD statements in red}, label=lst:transformation_fw, gobble=12]
             x1 = 15
            @rdx1 = 1@
             x2 = 7
            @rdx2 = 0@
             r1 = x1 + x2
            @rdr1 = dx1 + dx2@
             y  = r1 $\times$ x2
            @rdy  = r1 $\color{red}\times$ dx2 + dr1 $\color{red}\times$ x2@
        \end{quicklst}

        \begin{quicklst}[caption={An example of reverse mode AD by source transformation, with the AD statements in red}, label=lst:transformation_rv, gobble=12]
             x1 = 15
             x2 = 7
             r1 = x1 + x2
             y  = r1 $\times$ x2

            @rdy  = 1@
            @rdr1 = dy $\color{red}\times$ x2@
            @rdx2 = dy $\color{red}\times$ r1 + dr1 $\color{red}\times$ 1@
            @rdx1 = dr1 $\color{red}\times$ 1@
        \end{quicklst}
        
        For forward-mode AD, the evaluation of the derivative is done during execution.
        Like in 1996's FADBAD package, which provided both forward-mode and reverse-mode AD for C++ \cite{bendtsen1996fadbad}.
        The reverse-mode uses the taping method described by Griewank, implemented through a method called operator overloading.
        In forward-mode, operator overloading refers to providing the basic mathematical operators with methods that work on the numbers represented by a pair (of a primal part and a tangent part); this is the dual-numbers approach we mentioned before.
        For reverse-mode, operator overloading is used to rewrite the basic mathematical operators, so they record their use and intermediate values to a single tape data structure.
        A similar implementation was also provided by Griewank et al. in the 1996 package ADOL-C \cite{griewank1996algorithm}, again in 2001 using more efficient expression templates by Aubert et al. \cite{aubert2001automatic}, and later in 2014 by Robin Hogan \cite{hogan2014fast}.

        Source-code transformation is eventually also implemented, in the Tapenade AD program \cite{hascoet2013tapenade}.
        Tapenade adds derivative calculations to the code, but also employs lazy/delayed evaluation in the forward pass.
        This allows Tapenade to do some activity analysis, which in turn allows it to combine or discard some partial derivatives to be more efficient.
        It also implements the previously discussed checkpointing, where part of the tape is stored to be restored and differentiated later.
        This, in theory, allows for differentiating programs of arbitrary size, because the differentiation process is not limited by the size of the working memory \cite{griewank2008evaluating}.

        More recently implementations, like Fei Wang et al. 2019 paper, have shown how to simplify reverse automatic differentiation using continuation passing style and delimited continuations \cite{wang2019demystifying}.
        This method uses dual numbers and cleverly overloads operators so they call the forward pass as a continuation and then perform the backwards pass on the returned value.

        In 2022, Krawiec et al. show how reverse-mode AD can be extended efficiently to higher-order functional programs \cite{krawiec2022provably}.
        While the Wang paper also did this, Krawiec uses the functional nature to provide a correctness proof of the reverse-mode AD, something that had previously only been done on implementations that were either asymptotically inefficient or only worked on first-order languages.
        They do however need taping again to make it provable and efficient.\\
        V치k치r and Smeding provide a provably correct form of higher-order reverse AD without taping in their 2022 paper \cite{vakar2022chad}, based on earlier work by Elliott in 2018 \cite{elliott2018simple}.

        And in 2022 as well, Schenck et al. show how to do both forward-mode and reverse-mode automatic differentiation on second-order array language with nested data parallelism \cite{schenck2022ad}.
        They do this by eliminating taping again, which forces sequential execution, by allowing potential redundant execution.
        But by limiting their AD implementation to second-order functional languages, they can largely avoid this redundancy with efficient program transformations on parallel operators.

        Finally, in 2023, Smeding en V치k치r bring back explicit dual-numbers to reverse AD \cite{smeding2023efficient}.
        However, instead of pairing each number with its computed adjoint, they instead pair it with a linear backpropagator function, which they can then later chain to get the full derivative.
        While this initially seems to eliminate the need for taping, they find that through optimizations they return to a concept that is very close to taping and show that it is in fact equivalent.

    \subsection{Tracing}
        Tracing is a concept in computer science that is often left without proper definition.
        While the main ideas behind tracing are well known, they are generally assumed known by the reader and therefor left without explanation.
        This is also in part because, in software engineering, the term tracing also refers to finding the origin of some call (``tracing'' the call stack), which is only tangentially related to the tracing we are interested in, but can leave definitions of tracing a bit muddled.
        This is why, in Section \ref{sec:tracing}, we will discuss more about that proper definition.
        For now, it is important to know that, when we refer to tracing in this paper, we speak about tracing the path of computation through a program, given some (valid) input to said program.
        In other terms, given a program and an input, we walk through the program and record each computational step for some later purpose, like automatic differentiation.
        This recording can happen with some domain-specific pseudo-language, or in full fledged code if we wish to revaluate the trace later (or a combination of the two).

        Doing tracing gives us some interesting insights into a program we trace.
        First, it effectively ignores control flow.
        This is fairly intuitive, when given a set of inputs to a program, the control flow will control what path the program uses, and since we only record computations we find what is often dubbed a ``straight-line program'' for some inputs.
        This can be useful for instance in automatic differentiation, where we often only want to differentiate a computation, not the entire program including unused branches.
        This will also be the use of tracing in this paper, as laid out in Section \ref{sec:ad}.

        As mentioned, in literature we see this type of tracing used for automatic differentiation.
        One of these uses was by Bischof in 1991 \cite{bischof1991issues}.
        In his paper, Bischof discusses the use of the computational graph of a program in automatic differentiation (using ADOL-C \cite{griewank1996algorithm}).
        The computational graph of a program is an directed acyclic graph, where each node contains a computational step in the program, and edges connect these steps in the execution order of the program.
        Bischof creates this graph from the tape produced by ADOL-C, which makes sense: for automatic differentiation as discussed, the tape acts as a sort of trace, recording the steps that are important in the automatic differentiation.
        Bischof then uses a graph colouring algorithm on the computational graph to highlight ``component functions'' that may be differentiated concurrently, as to improve the running time of the algorithm.
        In 2008, Bischof et al. expand on this by extending the tracing automatic differentiation to loops \cite{bischof2008parallel}.
        They do this by extending ADOL-C, paying specific attention the parallelization opportunities present in automatic differentiation.

        In a similar vein, Dougal Maclaurin presented in his PhD thesis in 2016 \cite{maclaurin2016modeling} a paper introducing Autograd.
        A software package to automatically differentiate Python code (including AD for the vector library Numpy).
        As Python is an expressive JIT-compiled (Just In Time) dynamic language, they opt for tracing to construct the computing graph on the fly when a function is called, and like Bischof's work this allows them to do the backwards pass off reverse-mode AD on the computational graph.
        They do this by wrapping their variables as "nodes" in the computational graph.
        When a variable is used, it is first unwrapped for use, and then the result of whatever operation used the variable, is stored as a new variable and wrapped as well.
        The original variable and the produced variable are then linked such that the produced variable stores a reference to the original variable.
        This creates the reverse computational graph, which is exactly what is needed for the reverse AD pass.

        TensorFlow, a machine learning library, also uses tracing to create computational graphs \cite{abadi2016tensorflow}.
        This kind of tracing is not as low to the ground as actually following individual computations.
        Since TensorFlow mainly focusses on building artificial neural networks, the computational graph is made explicit by the programmer.
        While there are some nuance differences between a computational graph of a neural network and the neural network itself, these differences are somewhat unimportant.
        More interestingly, TensorFlow allows for the partial execution of the computational graph.
        While Bischof's use of a graph colouring algorithm already suggested this, TensorFlow actively uses this technique to re-run partial computational graphs, which works well for the explicit nature of neural networks, as the computational graph stays unchanged even if the inputs change (as neural networks do not have internal control flow).

        Finally, 2018's JAX uses tracing to enhance performance of general machine learning code \cite{frostig2018compiling}.
        The programmer annotates functions to be analysed by JAX, which then traces as optimizes them.
        Rather than finding the computational graph (or predefining it), JAX waits for Python to execute the function and actually traces it.
        Then, JAX optimizes it, mainly through a process called fusion, which is discussed in Section \ref{sec:bg_array}.
        This is also where JAX gets its name: Just After eXecution, as it waits for Python to execute the function first.
        It should be noted that JAX can only do this for functions which are pure-and-statically-composed (PSC), meaning functions that have no side-effects and that do not change with different inputs.
        Again, machine learning code is especially suited for this, as it often already satisfies this PSC assumption.
        
    \subsection{Functional Parallel Array Programming} \label{sec:bg_array}
        Array programming languages are programming languages that treat the array as a central data structure.
        This generally includes that functions, both user-defined and built-in, could be applied to arrays through vectorization.
        Vectorization involves applying a function to every element of an array at the same time.
        For instance, vectorization of addition would add two arrays together element-wise.
        This is shown in Equation \ref{eq:vectorization}, where $\vec{a}$ and $\vec{b}$ both are arrays of the same size.
        \begin{equation} \label{eq:vectorization}
            \vec{a}+\vec{b}=[a_1+b_1,\dots,a_n+b_n]\text{ iff }|\vec{a}|=|\vec{b}|
        \end{equation}
        In general vectorization would only work for arrays of the same size were it not for another central concept: broadcasting.
        Broadcasting involves the resizing of arguments to functions so they can be used.
        A very clear example would be if we wished to add a scalar value to each element in an array of scalars.
        To do this with vectorization alone would mean we'd need another array which replicates the scalar we wish to add for each element in the array we wish to add it to.
        Broadcasting basically does this for us, as exemplified in Equation \ref{eq:broadcasting}.
        \begin{equation} \label{eq:broadcasting}
            \vec{a}+2=[a_1+2,\dots,a_n+2]
        \end{equation}
        
        Array programming languages also often support higher-order operators for use on arrays.
        An important operator for arrays is fold (or reduce), which applies a binary function to elements in an array, where one argument accumulates the previous results.
        It is easy to imagine how such an operator could be used to, for instance, sum all the items in a 1-dimensional array.
        An important realization is that, since fold only returns the final result, fold can reduce the dimensions of an array by one.
        In our summation example, we fold a one-dimensional array into a zero-dimensional array, namely a scalar value.
        Similar to fold is scan, which like fold applies a cumulative binary function to each element in the array, but rather than returning only the result, it returns all intermediate results in an array (with the last element being the final result).

        Other important array functions include map, which applies a function to each element in an array.
        Then, forward permutation (scatter) and backwards permutation (gather), which permute one array into a new one by respectively mapping the indices of the source array to those of the new array or the indices of the new array to those of the source array.
        Generate, which generates a new array as well, but does by taking the dimensions of the desired array and a function that takes in an index and outputs a value.

        We should also not gloss over the actual implementation of these arrays, especially in functional languages where there exists two major ways of constructing arrays \cite{svensson2014defunctionalizing}.
        Pull-arrays are the more used of the two, here arrays are represented with a function from an index to a value.
        In push-arrays, consumers are provided with a method to write into memory.
        This means that the way that the efficiency of array operations can change based on the array representation.
        For instance, indexing is faster on pull-arrays while push-arrays are quicker to concatenate.
        This basically divides the array operations in two camps: push-operations and pull-operations.
        
        These two camps play an important role in a concept of fusion.
        When we have multiple back-to-back parallel array operations, executing them naively introduces a lot of overhead for reading and writing intermediate values to memory.
        Instead fusion allows us to combine these operations together, so we can compute them in one go without the overhead of storing intermediates.
        However, we cannot just go chaining parallel operations, not all parallel operations fuse together nicely.
        In fact, pull-array operations only fuse with other pull-array operations, and the same goes for push-array operations.
        This means for instance that we can fuse multiple scatter operations, but not a scatter and gather operation.

        Now the reason for choosing a (functional) array language over a general language is often because we need to process large amounts of numerical data, and arrays are well-suited for parallelism.
        To be precise, we are talking about data parallelism here.
        Task parallelism is when two or more computer processes run simultaneously on different processor cores.
        Data parallelism is when an operation (or a string of operations) is done element-wise on data structure like an array.
        The parallelism of data parallel processing of these operations on each element, rather than the parallelism of different processes.
        An important distinction between task and data parallelism, is that while parallel threads in task parallelism can generally start, run, and end independently of each other, data parallelism threads move in lockstep with each other.
        This is lockstep or synchronous execution means that the execution does not continue until the current operation has been applied to all elements in the array, which may be important if we want to do multiple parallel operations back-to-back.
        Furthermore, modern GPU architectures are especially well-suited for this type of synchronous parallelism, as graphics processing overlaps in large part with parallel array processing.

        A good starting point for the history of functional parallel array programming was in 1992, with G. Belloch's paper on the parallel array programming language NESL \cite{blelloch1992nesl}.
        The language was strongly-typed and had no support for side-effects, making it a functional language.
        The main way to add parallelism was through the inherently data-parallel ``vectors'' the language introduces in lieu of lists.
        These vectors could also be nested, and functions could run in nested parallel on these vectors.
        Another major inclusion was to allow user-defined functions to be run (in parallel) on these vectors, making it possible to write more complex nested data-parallel algorithms than before.

        The functional language Haskell, saw the introduction of task-parallelism well before its first official release, through libraries like pH \cite{maessen1995semantics}.
        Some data-parallelism followed \cite{hill1995data, herrmann1999parallelization, ellmenreich2000application}, but this was limited to applying a function over a flat array.
        However, in 2001 nested data-parallelism was introduced to Haskell by the NEPAL project by Chakravarty et al. \cite{chakravarty2001nepal}.
        The paper largely focusses on reimplementing NESL as a Haskell library, but creates a much more expressive data-parallel language doing so.
        This is because NESL was rather limited in scope, whereas Haskell was already a fully-fledged functional programming language.
        Two important concepts come to the forefront in the NEPAL paper, namely flattening and fusion.
        Both in NESL and in NEPAL, higher-dimensional nested parallelism is ``flattened'' to a single distributed parallel operation.
        In NESL, this meant that data-types had to be limited to tuples and the vectors it introduced, to make sure this flattening operation worked correctly.
        Since then however, Keller and Chakravarty had shown this flattening transformation could also be applied more generally to cover the full range of types of general programming languages \cite{keller1999transformation,keller1998flattening,chakravarty2000more}.
        This allowed them to apply the nested data parallelism of NESL to a more expressive language Haskell with NEPAL.
        Furthermore, they also showed that in combination with fusion it could produce efficient code for distributed machines \cite{chakravarty2001functional}.
        Fusion is where multiple separate parallel operations are combined into a single parallel operation, which greatly improves performance of complicated parallel programs.
        This is important because many operations on arrays introduce the need for intermediate arrays to be computed.
        Doing this in parallel leads to more problems, as these implementations rely on gang parallelism, where the parallel threads remain in lockstep with each other \cite{feitelson1996packing}.
        Fusion helps us here, as we can reduce the number of intermediate arrays to be generated, as we can calculate the results of multiple operations at once \cite{keller1999distributed,chakravarty2007data}.
        
        All this work culminated in 2007's Data Parallel Haskell (DPH) \cite{peyton2008harnessing}, by Peyton-Jones et al.
        Its main feature was the parallel array, that like NESL's vectors, was the main way of adding parallelism to a program.
        However, these parallel arrays could now hold any type, such as other arrays or functions, like Haskell's native (non-parallel) lists.
        Furthermore, DPH provides parallel variants of Haskell's native list functions, and a parallel alternative to Haskell's list comprehensions.
        The main difference between Haskell's native lists and DPH's parallel arrays (besides the parallelism) was that evaluating any value in a parallel array would require evaluation on all the array's elements, whereas Haskell as a lazy language would not normally do that.
        This is to be expected, as parallelism becomes meaningless if it is only applied to a single entry of an array.

        Outside of Haskell, a functional array-programming dialect of C was developed: Single Assignment C (SAC) \cite{scholz1994single, scholz2003single, grelck2005generic}.
        It would go on to distinguish itself as a functional array programming language in a style more familiar to programmers of imperative languages (like C).
        The main mechanic in SAC is the with-loop, which takes a generator that dictates a looping mechanism and an operation that dictates the return value.
        These operations can be functions like ``fold'' to reduce the rank of an array, or ``genarray'' to generate new (multidimensional) arrays.
        Besides the imperative style, the main draw of SAC is that its performance is comparable to Fortran and C, while its programs are generally more concise (for intensive numerical applications.)

        In 2010, Keller, Chakravarty, et al. presented a new data-parallelism approach for Haskell in ``Regular, Shape-polymorphic, Parallel Arrays in Haskell'' \cite{keller2010regular}.
        Previous approaches had focussed on irregular arrays, where on array could contain arrays of different lengths.
        The library Repa, introduced in this paper, was made for regular arrays where arrays of each nested rank are the same size.
        However, this allows the library to be purely functional and support shape polymorphism.
        While DPH was purely functional as well, it wasn't especially performant on regular arrays and it also did not support shape polymorphism.
        In shape polymorphism, the type of a collection is fixed (unlike in type polymorphism), but the shape of the collection is not \cite{jay1994shapely}.
        For instance, under shape polymorphism a function may be applied to either a flat array, or a 10-dimensional one.
        While shape polymorphism for functional arrays had been implemented before in SAC, Repa implemented it by embedding it into Haskell's type system, whereas the SAC implementation had required a purpose-built compiler.
        This also allowed programmers to more easily see and control the shapes of their multidimensional parallel arrays, and build their own shape polymorphic parallel functions.

        In 2011, Repa was succeeded by the Accelerate project \cite{chakravarty2011accelerating}.
        Accelerate is a library for Haskell, aimed specifically at bringing parallel array programming to modern GPUs.
        It mimicked many of Haskell's native list functions with parallel alternatives (that run on the GPU), and used the typed shaped polymorphism from Repa.
        It also separated ``collective'' (array) computations and scalar computation by wrapping these in Haskell monads.
        Here, collective computations could include scalar computations, but not the other way around.
        This meant excluding nested and irregular data parallelism, which in turn allows Accelerate to efficiently run on GPUs (which are much more constrained than CPUs).
        It also meant that these arrays could only contain scalars, no functions or other types.
        
        Another interesting example of a parallel array programming language is Remora by Slepak et al. \cite{slepak2014array}
        The language, inspired by earlier array programming languages APL \cite{iverson1962programming} and J implements rank-polymorphism.
        Rank polymorphism is similar to shape polymorphism, but it annotates functions and operators with an array rank they can operate on, and was also present in Repa and Accelerate.
        Remember that scalars are considered rank 0 arrays, a flat array is rank 1, a matrix is rank 2, et cetera.
        In rank polymorphism, arguments are transformed (re-ranked) such that they are the rank required for a specific function or operator.
        Specifically, an operator defined for a certain rank, is automatically defined for any higher rank, because it can be mapped over these higher dimensions.
        This is subtly different from the more general shape-polymorphism, as rank only refers to the number of dimensions, while shape also contains information on the size of these dimensions.
        With Remora, Slepak et al. tried to shed some light on the more ``murkier corners'' of the array-computational model.
        They do this by generalizing the array-computational model, which then allows them to both address some of the shortcomings of APL, but also allows them to extend the model to allow arrays of functions and arrays of arguments, which in turn allows for the parallel MIMD (multiple instruction, multiple data) architecture, rather than only SIMD (single instruction, multiple data) parallelism.

        In 2017, we got one of the major current functional data-parallel array languages in Futhark \cite{henriksen2017futhark}.
        Futhark's design focusses on efficient nested data-parallelism.
        They do this by using both ``aggressive'' fusion (fusing as much as possible), followed by flattening (like we saw in NESL).
        Finally through some more optimizations, Futhark produces very performant programs.
        To facilitate this performance however, they do not support higher-order programming, as Futhark only supports up to second-order.

        Finally, a more recent parallel array programming language is Dex \cite{maclaurin2019dex,paszke2021getting}.
        Rather than avoiding loops and explicit indexing, like NESL, NEPAL, DPH, and Repa had all done, Dex suggests that these features might introduce more clarity, if only they were implemented correctly.
        The main idea is to treat index sets as types and arrays as functions.
        In reality this ``index comprehension'' can also be seen as functions that return arrays, and allow declaring iteration over multiple dimensions in a single line.
        Of course, this is the same idea as pull-arrays, a representation also used by Accelerate under the hood.
        However, the main novelty of Dex is that they use this to make explicit loops, which in turn makes some parallelism opportunities also explicit.
        Also when these index comprehensions are presented back-to-back, opportunities for fusion become fairly clear as well.
        In their paper, they also show that on some benchmark problems, Dex performs similarly to Futhark, as a functional array programming language that was specifically designed to write performant parallel GPU code.
