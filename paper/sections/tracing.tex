\section{Tracing} \label{sec:tracing}
    In the broadest terms, when we trace a program, we track the most basic steps the program takes provided some input.
    This is relevant for many applications in computer science.
    For example, certain automatic differentiation (AD) effectively implement the forward-pass as tracing, and then perform the reverse pass on the trace.
    Tracing is also used in artificial intelligence, where tracing applications can help determine how much memory needs to be allocated, which can speed up training if the model is run multiple times.

    However, despite its ambivalence, tracing is rarely properly defined, or defined only for a specific use case.
    So, in this section we set out to create a more general definition of tracing.
    
    To start, it will help us along to set clear expectations for what we want a tracing function to do.
    In the simplest terms, we expect a tracing program to take an input program with a set of inputs, and output a ``trace''.
    This output trace is defined as a sequence of operations the input program performed on the inputs to get the expected output.
    A term often used for a trace is a ``single-line program'': a program without control flow.
    Clearing control flow like if-then-else statements is only natural: after all, provided some input the program will only walk down one variation of this branching path.

    Furthermore, it is also generally accepted that the trace consists of a subset of the types in the input program.
    Because we are generally more interested in what happens to the data in our program, we can ``trace away'' functions and data structures.
    More precisely, say our input program has the types as defined in Equation \ref{eq:typebase}, where we have sum-types as $\tau+\sigma$, product types as $\tau\times\sigma$, functions as $\tau\to\sigma$, literal real numbers, and literal Booleans.

    \begin{equation}
        \label{eq:typebase}
        \tau,\sigma\coloneqq\tau+\sigma\|\tau\times\sigma\|\tau\to\sigma\|\mathbb{R}\|\mathbb{B}
    \end{equation}

    We can imagine our simplified language, in which we will express our trace -- as a language with fewer type formers.
    By choosing a subset of the type formers in our program, we can indicate which data structures should be traced away.
    A common option is to keep only ``ground types'', where we defined a ground type as a type that is not constructed of other types.
    Looking at our example in Equation \ref{eq:typebase}, a trace keeping only these ground types would keep only the real numbers and the Booleans as they are not built of other types.
    Another common option is to keep only continuous types, tracing away all unground and discrete types.
    Doing that on our type set in Equation \ref{eq:typebase} would leave us with only the real numbers.
    This is under the assumption that the discrete types are not actually used as data we are interested in tracing of course, but since tracing will remove all control flow from the program, keeping Booleans and operations on Booleans intact may be meaningless. 

    The main take-away here is that there is some freedom of choice in what to trace away.
    What parts we keep and what parts we trace away is very dependent on what information we want to keep in our trace, which in turn is dependent on what our exact goal is for the tracing in the first place.
    
    We can also choose to keep some of our unground types, but then we run into a problem.
    Say we keep only functions ($\tau\to\sigma$) and real numbers, but our input program contains a function with type $\tau\to(\sigma_1+\sigma_2)$.
    This typing is valid in our input program, but no longer valid in our trace, so we find ourselves in a bind.
    It will be impossible to trace away the sum-type in the output of the function without tracing away the function itself.
    This is because tracing something away basically means either deconstructing or ignoring it in the trace.
    For instance, tracing away a tuple, would mean tracing the individual components of that tuple to trace it away.
    Whereas keeping things in the trace means just keeping them untouched.
    Therefore, we cannot keep a type like a function $\tau\to(\sigma_1+\sigma_2)$ in our trace, because we cannot access the sum type without tracing away the function.
    Of course, we could define a subset $\tau',\sigma'\coloneqq\mathbb{R}$ and then redefine (or add a definition for) our function so that it becomes $\tau'\to\sigma'$ making it safe to trace.
    This then underlines the rule at work here: we can only keep types that do cannot be constructed of types that are traced away.
    This is why the ground types are a natural set of types to keep, as they are never constructed from other types.
    
    In a similar vein, we may also encounter operators in our trace that take in or produce types that are not allowed in our trace.
    For operators that produce a type that is not in our trace, tracing them away is no problem.
    Since we know we will not be interested in whatever output they produce for our trace, we can simply omit them from the trace altogether.
    For instance, if we keep only real numbers in our trace like before, an operator returning a Boolean value is of no interest for the trace.
    However, this is not a simple for operations that take in a type we wish to trace away, yet produce a type we wish to keep in our trace.
    A simple example of this is the ``switch'' operator, which takes in a Boolean value and two values of another type, of which it returns one depending on the Boolean value (see Equation \ref{eq:switch}).
    \begin{equation}
        \begin{aligned}
            \texttt{switch}(\top,a,b)&=a\\
            \texttt{switch}(\bot,a,b)&=b
        \end{aligned}
        \label{eq:switch}
    \end{equation}
    While the switch operator looks like it mimics if-then-else statements, it is generally accepted that it does so in a non-lazy way, where both $a$ and $b$ are evaluated before returning either.
    The main problem here is that we wish to keep operators that produce types we keep in our trace, yet we do not wish (or are not even able to) express the Boolean value in our trace.
    Now, due to switch statement's likeness to if-then-else, the solution here is pretty clear: only trace the value that gets returned.
    However, it is not always that easy: as we introduce arrays and array operations in Section \ref{sec:arrays}, we will see how operations like mapping on an array need a special solution.
    
    This all is to say that the while we can either ignore or homomorphically copy basic operations for our trace, sometimes we need a special solution.
    Mainly because we do not want to lose the information that is needed to execute the trace as a single-line program, even if that means fudging our operations a little.
    This also means that, while the operations in our trace language might be a subset of the operations in the original expression language, they might contain modified operations

    It seems that our tracing definition comes down to a function that takes in a program and an input to that program, and outputs the steps taken by the program run on the input.
    Where the input program uses some set of types, of which only a subset is kept in the trace, where the types in this subset may not be constructed using types from outside the subset.
    What now remains is a concrete definition of the output of the tracing program.
    We have already stated that it should somehow contain the steps done by the input program.
    The steps we wish to record are generally basic operations like arithmetic operations.
    But other operations, such as operations on arrays, can also be added depending on the ultimate goal of the tracing.
    More importantly, as we expect our trace to be akin to a single-line program, we may consider our trace as a series of let-bindings, akin to A-normal form.
    This means storing each operation as a pair of a unique name or ID and the operation performed (like the name and value of the declarations in a let-binding).
    
    \subsection{Tracing Correctness} \label{sec:correctness}
        Before going into specifics on how to implement tracing, it would also be a good idea to formalize when a trace is actually correct.
        Like we posed before, we start with some program formed from some expression language $S$, and some input $I$ that is valid for that program.
        If we wish to resolve a program $S$ on input $I$, then we would need some evaluation function that produces the expected output $O$.
        Now, given some trace language $T$ we can write a tracing function that gives us the trace and output of a specific program and input combination.
        We can write this out as the two functions \texttt{eval} and \texttt{trace} in Equation \ref{eq:evalntrace}.
        \begin{equation}
            \begin{aligned}
                \text{eval}&:S\times I\to O\\
                \text{trace}&:S\times I\to T\times O
            \end{aligned}
            \label{eq:evalntrace}
        \end{equation}

        With this we can formalize two criteria for our trace.
        First, the trace, as a single line program $t\in T$ produced by the trace function needs to produce the correct output.
        Now, as mentioned before, $t$ might contain transformed operations, that are not present in $S$.
        Therefore, we either need to look at traces $t\in S\cap T$, or use a different evaluation function.
        For now, we will use the former to assert the output criterium in Equation \ref{eq:output}.
        Here we state that for any program $s$ with any input $i$: if the trace $t$ is also a valid program in $S$, that the evaluation of $t$ on $i$ should be the same as the evaluation of $s$ on $i$ or the output $o$ we got out of the tracing function.
        \begin{equation}
            \begin{aligned}
                &\forall s\in S\\
                &\forall i\in I\\
                &\text{trace}(s,i)=(t\in T,o\in O)\\
                &(t\in S\cap T)\to(\text{eval}(s,i)=\text{eval}(t,i)=o)
            \end{aligned}
            \label{eq:output}
        \end{equation}

        Furthermore, tracing a trace $t$ should also return that trace $t$.
        This is because we want to find the minimal straight-line program using tracing, and if tracing the trace we found reduces it somehow to a more minimal program, we know that the original trace was incomplete.
        This is expressed in Equation \ref{eq:mintrace}, where we assert that for some program $s\in S$ and some input $i\in I$, the trace $t$ (produced by tracing $s$ on $i$), is the same as the trace obtained from tracing $t$ itself.
        \begin{equation}
            \begin{aligned}
                &\forall s\in S\\
                &\forall i\in I\\
                &\text{trace}(s,i)=(t\in T,o\in O)\\
                &\text{trace}(t,i)=(t,o)
            \end{aligned}
            \label{eq:mintrace}
        \end{equation}

        The above statements, assert that a trace should produce the correct output value as expected from the input program, and that a trace should be its own trace.
        While these assertions do not say a lot about the nature of the actual trace, they do set some baseline requirements for the trace, and proving the correctness of a trace.
        This vagueness on the contents of the trace is partly because we cannot really say anything about a trace without dissecting the source program as well, which would bring us to a point very close to actual tracing itself.
        In another part however, this is because we do not want to make any assumptions what can or cannot be in our trace.
        While it is likely that some there is significant overlap between $S$ and $T$, as mentioned, we might need some additions to $T$ to actually be able to trace everything in $S$ correctly.
        Also, whilst in practice it might be meaningless, a trace where $T=\emptyset$ is in itself not incorrect: any trace would simply be empty.
        In a similar vein a trace where $S\subseteq T$ would also be meaningless in practice, it is also not wrong: any trace would simply be the same as the source program.

        As an additional note, Equation \ref{eq:output} also implies something interesting.
        If we want our trace to output the same value as the original program, we cannot trace away the type of the original programs output.
        Say we trace away Boolean values when we are tracing a program that returns a Boolean value, then we find ourselves stuck, because we trace away all operations that produce Boolean values.
        And of course, if our trace is not allowed to produce any Boolean values, we cannot produce the required output either.
        Therefore, we must assure that the type of the output is valid in our trace as well.

    \subsection{Basic Tracing} \label{sec:steps}
        We now define some basic tracing steps for some arbitrary language.
        For clarity's sake, we will do this is with Haskell code.
        To do this we first define a language and values on which we will operate.
        We do this in Listing \ref{lst:language}, where we define a basic lambda calculus.
        Here the value types are represented as the algebraic data type (ADT) \texttt{Value}, where we find constructors for Booleans (\texttt{VBool}), real numbers (\texttt{VReal}), and functions (\texttt{VFunc}).
        Then we define the four terms of a basic lambda calculus in the \texttt{Expression} ADT: application (\texttt{EApply}), abstraction (\texttt{ELambda}), loose values (\texttt{ELift}), and variable reference (\texttt{ERef}).
        To make tracing a little more interesting we also add in if-then-else statements (\texttt{EIf}) and binary operators (\texttt{EOp2}).
        For those binary operators, we define four operations in the separate \texttt{Op2} ADT: addition (\texttt{Add}), equality (\texttt{Equ}), multiplication (\texttt{Mul}), and inequality (\texttt{Neq}).
        Finally, to make use of variable references, we define an environment as a mapping of strings to values.
        We interact with this environment in two ways: by inserting values into them, and getting values from them (indexing).
        The function signatures for these interactions, respectively \texttt{insert} and \texttt{(!)}, have been included in Listing \ref{lst:language} as well.
        We can use this language and evaluate it, an example of this has been provided in Appendix \ref{sec:eval}.

        \begin{haskell}[caption=Minimal lambda calculus with added if-then-else and binary operators, label=lst:language, gobble=12]
            data Value = VBool Bool | VReal Float | VFunc (Value -> Value)

            data Expression
                = EApply  Expression Expression
                | EIf     Expression Expression Expression
                | ELambda String     Expression
                | ELift   Value
                | EOp2    Op2        Expression Expression
                | ERef    String

            data Op2 = Add | Equ | Mul | Neq

            type Environment = Map String Value

            -- Operations on maps:
            -- (where Map a b is a mapping from keys of type a to values of type b)
            insert :: a -> b -> Map a b -> Map a b
            (!) :: Map a b -> a -> b
        \end{haskell}

        With our language in Listing \ref{lst:language}, we can almost start tracing.
        However, we must first decide which parts of the language we keep, and which parts we wish to trace away.
        In the previous section, we talked about how we can do this by selecting which type formers we wish to keep.
        In Listing \ref{lst:language}, we have practically defined the types of our values by the data constructors present in the \texttt{Value} ADT as Booleans, real numbers, and functions.
        Let us now choose to keep only real numbers in the trace.

        We now define a new ADT for traced values in Listing \ref{lst:traced}.
        This is only so we can incorporate a name into the values we wish to keep in our trace.
        These names will help us read the trace, and can be incrementing numbers or something entirely random, as long as they are unique.
        The basic idea is here to feed the \texttt{trace} function a number with which to generate the steps' names from, and increment the number every time we do.
        However, since this clutters the code while not being very interesting, we will assume we have some function \texttt{getName} that provides us with a unique name.
        Furthermore, it is important to see that we still have Boolean values and functions in our \texttt{TValue} ADT, even though we only wish to keep real numbers in our trace.
        This is because we might still need these values to resolve expressions, even if they never end up in the trace.
        We might also achieve this by extending our original \texttt{Value} ADT (from Listing \ref{lst:language}) with traced variants of values, but this is merely a point of preference.
        Finally, we have also changed the signature of the function value to return a trace as well, as we move on to functions we will see how this works.
        
        \begin{haskell}[caption=Basic trace building blocks, label=lst:traced, gobble=12]
            data TValue = TBool Bool
                        | TReal String Float
                        | TFunc (TValue -> (TValue, Trace))

            data Traced = TLift TValue | TOp2 Op2 String String
            
            type TEnvironment = Map String TValue

            type Trace = [(String, Traced)]

            getName :: String
        \end{haskell}

        First however, with our basic building blocks for tracing set up, lets trace away these boolean values.
        We do this with the trace function in Listing \ref{lst:trace_bool}.
        For now, we will leave out abstraction and application, as it might be easier to talk about tracing away Booleans first.

        \begin{haskell}[caption=Tracing away Boolean values, label=lst:trace_bool, gobble=12]
            trace :: TEnvironment -> Expression -> (TValue, Trace)
            trace n (EIf e1 e2 e3) =
                -- Since we e1 should resolve in a Boolean value, we do not need to trace it.
                let v1 = eval n e1
                in  case v1 of
                    -- We can check for the type of v1 and its value in one go
                    -- We trace only the relevant branch
                    (VBool True)  -> trace n e2
                    (VBool False) -> trace n e3
                    _             -> error ``Type mismatch in trace/EIf''
            
            trace n (ELift v) =
                -- Check if v is a value we would like to trace
                case v of
                    -- If yes return the transformed value with its simple trace
                    (VReal v) ->
                        -- Generate a name for this step and make the TValue
                        let s  = getName
                            v' = TReal s v
                        -- Combine the TValue with a trace of its instantiation
                        in  (v', [(s, v')])
                    -- If we do not wish to trace something, we can just return the value 
                    -- with an empty trace.
                    (VBool v) -> (TBool v, [])
                    -- Instantiation is not allowed for functions, they need to be 
                    -- abstracted using ELambda
                    _         -> error ``Type mismatch in trace/ELift''

            trace n (EOp2 op e1 e2) =
                -- We again first trace e1 and e2
                let (v1, t1) = trace n e1
                    (v2, t2) = trace n e2
                    -- We get a ready name in case we need it
                    s = getName
                -- This case syntax allows us to select for the right operator with the 
                -- right value types at the same time.
                in  case (op, v1, v2) of
                    -- Since add and mul take in reals and produce one too, we trace both 
                    -- the operation and the origins of v1 and v2
                    (Add, TReal s1 a, TReal s2 b) -> (TFloat s (a + b),
                        (TOp2 op s1 s2) : t1 ++ t2)
                    (Mul, TReal s1 a, TReal s2 b) -> (TFloat s (a * b),
                        (TOp2 op s1 s2) : t1 ++ t2)
                    -- For operations producing Bools we only return the result, but they
                    -- are not traced, and therefor return an empty trace
                    (Equ, TBool _  a, TBool _  b) -> (TBool (a == b), [])
                    (Equ, TReal _  a, TReal _  b) -> (TBool (a == b), [])
                    (Neq, TBool _  a, TBool _  b) -> (TBool (a /= b), [])
                    (Neq, TReal _  a, TReal _  b) -> (TBool (a /= b), [])
                    _                             -> error ``Type mismatch in trace/EOp2''

            -- There is nothing to trace when fetching a variable, but we still need to
            -- actually get the value
            trace n (ERef s1) = (n ! s1, [])
        \end{haskell}

        When we trace away Booleans, like in Listing \ref{lst:trace_bool}, it is useful to think about where these Boolean values actually come up.
        In our minimal language from Listing \ref{lst:language}, there are only three points: when they are included as literal values, as the input or output to basic operations, or as the conditional in if-then-else statements.
        
        Let us start with the easiest first: literal Boolean values.
        When we encounter literal values during tracing, and they are of a type we wish to keep for our trace, we simply add their instantiation to the trace (as \texttt{TLift} in Listings \ref{lst:traced} and \ref{lst:trace_bool}).
        This is extremely straightforward: those values might be used by the operations we wish to trace, so they should be included in the trace themselves as well.
        For values of types we wish to trace away, we simply do not include them in the trace.
        After all, our trace should be fine without them, as we do not include any operations that require them in our trace, right?
        For now this seems obvious: if we look at the language in Listing \ref{lst:language}, we see that there are no other uses for Booleans values than the use in the equality and inequality operators, and as the conditional in the if-then-else statement.
        Since we plan to trace these away, we do not appear to need these value instantiations in our trace either.
        However, at the end of Section \ref{sec:correctness} we already discussed what would happen if our program were to return a Boolean value.
        And in Section \ref{sec:arrays}, we will see how this might not be entirely true when we talk about arrays and operations on arrays like mapping a function.
        
        Tracing (away) simple operations like addition and equality (\texttt{EOp2}) are done in a similar vein.
        If the operation returns a value of a type we wish to keep in our trace, we include the operation in our trace as well.
        Similarly, if the operation returns a value that we do not wish to keep, we simply do not trace it.
        Again, if there was an operation that took in a value of a type we do not wish to trace, and returned one that we do wish to trace we run into a problem.
        Luckily, these operations are not included in our current example.

        When we trace an if-then-else statement, we know we have to deal with a Boolean regardless.
        Luckily for us, we know we only need to trace one of the branches.
        This means quite simply, that we can ignore the if-then-else statement, and act like the program continued at the branch that is chosen.
        Since the input is provided, we can resolve the conditional immediately, and then just trace the appropriate branch.

        Finally, tracing variable references are simple as well.
        Currently, the only named variables that occur are those created in lambda abstractions or those that are provided as inputs.
        But no matter how they are created, variable reference does not require tracing.
        This is because the trace will reference the values regardless of whether they are instantiated on the spot or somewhere previously.
        And if they were defined previously, that definition is already in the trace somewhere.

    \subsection{Function Tracing} \label{sec:functions}
        With our basic tracing established, we can now talk about tracing functions, which are more complicated.
        It is the tracing of abstracted functions that is the first issue here.
        The issue is that when we perform an abstraction (as with \texttt{ELambda}), there is nothing to trace.
        In fact, we can see this as an instantiation of a function literal, and when functions are not in our set of types to keep in the trace, this abstraction creates an empty trace.
        However, leaving it at that would mean we never actually trace the body of the function.
        Yet, at the time of the abstraction, we also do not yet know the input to the function either, meaning we cannot trace the body at that time.
        We must instead consider how we delay tracing until the function is actually applied.
        This is where our notation for \texttt{TFunc} (as in Listing \ref{lst:traced}) comes up.
        We wish that functions while tracing perform tracing themselves, thus return a \texttt{Trace} together with the return value.
        This is then what we do in the abstraction step: we set the trace on the body of the function as the body of the function we return.
        Similarly, we also give this tracing function call the environment at the time of abstraction, allowing the function body to access any free variables that were defined at that time.
        This makes application also very simple: we apply the function, and then just combine the trace of the function's instantiation, with that of the argument, and that of the function's execution.
        We also trace the function's instantiation, since at the time of application we do not know if the expression that leads to the function does anything else that we might need to trace as well.
        Finally, this is results in what we see in Listing \ref{lst:trace_func}, where we left out any patterns of trace that were already present in Listing \ref{lst:trace_bool}.

        \begin{haskell}[caption=Tracing away functions, label=lst:trace_func, gobble=12]
            trace :: TEnvironment -> Expression -> (Value, Trace)
            trace n (EApply e1 e2) =
                -- First trace e1 and e2
                let (v1, t1) = trace n e1
                    (v2, t2) = trace n e2
                -- Check if v1 actually returns a function
                in  case v1 of
                    -- Do the application, return the result and the combined trace
                    TFunc f -> let (vf, tf) = f v2
                               in  (vf, tf ++ t2 ++ t1)
                    _       -> error ``Type mismatch in trace/EApply''
            
            trace n (ELambda s e1) =
                -- Define the function, insert value x as variable s into the environment that is currently 
                -- present, and trace the body
                let f = TFunc ($\backslash$x -> trace (insert s x) e1)
                -- Return the function as abstracted function as a value, and no trace
                in  (f, [])
        \end{haskell}

        \clearpage
        \begin{haskell}[caption=Tracing let bindings, label=lst:trace_let, gobble=12]
            data Expression
                = $\ldots$
                -- The string here is the name of the bound variable
                | ELet String Expression Expression

            trace :: Environment -> Expression -> (TValue, Trace)
            trace n (ELet s1 e1 e2) =
                -- Evaluate e1 first, then e2 with e1 in its environment
                let (v1, t1) = trace n e1
                    (v2, t2) = trace (insert s1 v1 n) e2
                -- Return the value of e2 and the combined trace
                in  (v2, t1 ++ t2)
        \end{haskell}

        \subsubsection{Tracing let bindings} \label{sec:structures}
            As an additional structure present in functional languages that we might wish to trace, there are let-bindings.
            Recall that let-bindings are effectively the same a lambda abstractions that are resolved immediately.
            This makes it extremely easy to resolve them, because we can just trace the let-side of the binding and add it to the environment for the tracing of the right-hand-side.\\
            Adding let-bindings and tracing them is done in Listing \ref{lst:trace_let}.  

    \subsection{Array Tracing} \label{sec:arrays}
        Tracing on data structures like arrays provides us with a new problem that revolves around whether we wish to trace arrays away or not.
        We can see arrays as either structures that contain the data we are really after, which would require us to trace them away, or as data in their own right which we wish to keep in the trace.
        Both scenarios provide us with interesting challenges.
        
        Let us first talk about tracing arrays away.
        When we simply view arrays as another computational structure, they are not too complicated to trace away.
        When initializing an array, we just initialize all the individual values in the array.
        And when performing operations on items in the array, we instead perform those operations on the individual items again.
        That is, we do the operation like normal, but denote them as operations on separate items in the trace.
        
        In Listing \ref{lst:language_array} we first add a arrays and array operations.
        While we said earlier that constructors in the \texttt{TValue} ADT only needed strings for names if they are traced, we need to make an exception for arrays.
        This is because when working with arrays our expression will never refer to individual values in arrays, only to the array itself (and using its individual values from there).
        This means that to consistently refer to values that were in arrays in the original expression, we need to give a little more structure to the naming scheme.
        We do this by taking the name of the array, and adding the index of the item to create a name that is unique yet identifiable. 
        Furthermore, we add in array operations: iota (or range) (\texttt{Iota}), generate (\texttt{Gen}), indexing (\texttt{Idx}), sum (\texttt{Sum}), map (\texttt{Map}), and folding (reduction) (\texttt{Fold}).
        It should be noted that iota, generate, and indexing take an integer argument as part of their operator.
        For iota and generate this is the size of the array to create, and for indexing this is the index to get the value from.
        While we could allow our language with integers (or by casting floats) to allow using in-language numbers, this really is not all that interesting.
        If those arguments were part of our trace, it would just mean tracing them like any other item by just ignoring them.

        \begin{haskell}[caption=Adding arrays, label=lst:language_array, gobble=12]
            data Value = $\ldots$ | VArray [Float]
                
            data TValue = $\ldots$ | TArray String [Float]

            data Expression
                = $\ldots$
                | EOp0 Op0
                | EOp1 Op1 Expression
                | EOp2 Op2 Expression Expression
                | EOp3 Op3 Expression Expression Expression

            data Op0 = Iota Int
            
            data Op1 = Gen Int | Idx Int | Sum

            data Op2 = $\ldots$ | Map

            data Op3 = Fold
        \end{haskell}

        Now with arrays added to our language, we can actually trace them.
        This is done in Listings \ref{lst:trace_array} and \ref{lst:trace_array2}, where we again extend the trace function, leaving out any patterns that remain unchanged.
        
        First off, when encountering a literal array, or creating one with the iota operator, we need to initialize every individual value.
        This is fairly simple, it just requires us to walk through the array and initialize every value like when we were initializing literal real values.

        Indexing, in this mode, is equal to variable reference due to our naming scheme.
        This means then that we do not need to trace anything here.

        \begin{haskell}[caption=Tracing away arrays, label=lst:trace_array, gobble=12]
            trace :: TEnvironment -> Expression -> (TValue, Trace)
            trace n (ELift v) =
                case v of
                    -- Tracing for reals and Booleans remain unchanged
                    (VReal  v) -> $\ldots$
                    (VBool  v) -> $\ldots$
                    (VArray v) -> let s = getName
                                  -- For traceArrayLift see Listing !*\ref{lst:trace_map}*!
                                  in  (TArray s v, traceArrayLift s v 0)
            
            -- With only iota, we could write this a little more curtly, but for clarity we leave it like this
            trace n (EOp0 op) =
                case op of
                    (Iota r) -> 
                        let s = getName
                            -- Define an array of size r, then lift is using traceArrayLift again
                            v = [0.0 .. (r - 1)]
                            -- For traceArrayLift see Listing !*\ref{lst:trace_map}*!
                        in  (TArray s v, traceArrayLift s v 0)
            
            trace n (EOp1 op e1) =
                -- Again we first trace e1, and we get a name ready as well
                let (v1, t1) = trace n e1
                    s = getName
                in  case (op, v1) of
                    (Gen r, TFunc f) ->
                        let v  = [0.0 .. (r - 1)]                            
                            tg = traceArrayLift s v 0
                            (vm, tm) = traceArrayMap f s v 0
                        in  (vm, tm ++ tg)
                    -- Indexing is like variable reference, we do not need to add to the trace,
                    -- but we need to create the name to be consistent
                    (Idx i, TArray s1 v) ->
                        -- Get the actual item using indexing (!!)
                        let x  = v !! i
                            s' = s1 ++ `!' : show i
                        in  (TReal s' x, t1)
                    -- For traceArraySum see Listing !*\ref{lst:trace_sum}*!
                    (Sum, TArray s1 v) ->
                        let (vs, ts) = traceArraySum s1 v 0
                        -- We must not forget to add the trace of e1 to our trace here
                        in  (vs, ts ++ t1)

            -- See Listing !*\ref{lst:trace_array2}*! for trace on EOp2 and EOp3.
        \end{haskell}

        \begin{haskell}[caption=Tracing away arrays in maps and folds, label=lst:trace_array2, gobble=12]
            trace n (EOp2 op e1 e2) =
                -- Again we first trace e1 and e2, and we get a name ready as well
                let (v1, t1) = trace n e1
                    (v2, t2) = trace n e2
                    s        = getName
                in  case (op, v1, v2) of
                    $\ldots$
                    (Map, TFunc f, TArray sa va) ->
                        -- For traceArrayMap see Listing !*\ref{lst:trace_map}*!
                        let (vm, tm) = traceArrayMap f sa va 0
                        -- Combine the traces
                        in  (vm, tm ++ t1 ++ t2)

            trace n (EOp3 op e1 e2 e3) =
                -- Again we first trace e1, e2, and e3, and we get a new name ready
                let (v1, t1) = trace n e1
                    (v2, t2) = trace n e2
                    (v3, t3) = trace n e3
                    s        = getName
                in  case (op, v1, v2, v3) of
                    (Fold, TFunc f, TReal {}, TArray {}) ->
                        -- For foldFunction and traceArrayFold see Listing !*\ref{lst:trace_fold}*!
                        let (vf, tf) = traceArrayFold (foldFunction f) v2 v3 0
                        -- Combine the traces
                        in  (vf, tf ++ t1 ++ t2 ++ t3)
        \end{haskell}

        The sum operator is a little more in-depth, as shown in Listing \ref{lst:trace_sum}.
        However, this is a lot of code for a very simple principle, and a couple edge cases.
        The principle is, add the first two values in the array together, and then every following item to that result and so on.
        And we have edge cases for singleton and empty arrays.
        It is worth explicitly stating that every addition done whilst summing the array gets its own unique name and step in the trace.
        This means that an operation that is single step the original program, explodes to a bunch of steps (the length of the array minus one) in the trace.
        This is because we decided to trace away arrays, and we will see later on how we save ourselves from this by not tracing away arrays.

        The map operator is funky in a way similar to sum.
        In essence, we take each item in the array and apply it to the function as expected.
        However, we run into a little problem with our naming scheme.
        For map, the items, once mapped on, are placed back into a new array.
        This means that, according to the scheme we laid out, the items in this array should be named in reference to the new array, however this is not something the call to trace in the function body considers.
        Luckily we can resolve this by renaming the returned value from that function, and changing the name in the trace.
        The signature of a function that does this is also included at the end of Listing \ref{lst:trace_map}, but its exact implementation is not of importance here.

        Finally, the generate operation can be expressed as an iota operation followed by a map operation.
        The iota operation provides us with the indices of the array to generate, and we can re-use the code for map for mapping the generator function over these indices.
        This is also how we implemented it in Listing \ref{lst:trace_array}, using \texttt{traceArrayLift} from iota and \texttt{traceArrayMap} from map.

        \begin{haskell}[caption=Tracing the sum operator, label=lst:trace_sum, gobble=12]
            -- traceArraySum starts the trace, and traceArraySum' completes it
            -- This is necessary because we do not know the number of items in the array
            -- traceArraySum takes only the array to sum
            traceArraySum (TArray _ []) =
                let s = getName
                    v = TReal s 0
                -- The sum of an empty array means just lifting the value 0
                in  (v, [(s, TLift v)])

            traceArraySum (TArray _ [x]) =
                let s = getName
                    v = TReal s x
                -- The sum of a singleton array is just that one value
                in  (v, [(s, TLift v)])

            traceArraySum (TArray sa (x:y:z)) =
                -- When summing on a larger array, the first sum is of the first two items
                let sx = sa ++ ``!0''
                    sy = sa ++ ``!1''
                    s  = getName
                    v  = TReal s (x + y)
                    -- Get the result, and the trace of the rest of the array with traceArraySum'
                    (rv, rt) = traceArraySum' (TArray sa z) 2 v
                -- Return the final result, but do not forget the trace of the first sum
                in  (rv, (s, TOp2 Add sx sy) : rt)

            -- traceArraySum' takes the array we sum over, the current index, and the last calculated value
            traceArraySum' :: TValue -> Int -> TValue -> (TValue, Trace)
            -- When we are done, return the value
            traceArraySum' (TArray _ []) _ v = (v, [])
            
            traceArraySum' (TArray sa (x:xs)) i (TReal sr r) =
                -- Get the name for this item
                let sx = sa ++ `!' : show i
                    -- Get the name for this addition step
                    s  = getName
                    -- Get the result of the rest of the array
                    (v, t) = traceArraySum' (TArray sa xs) i (TReal s (x + r))
                -- Return the final result, and add this steps addition to the trace
                in  (v, (s, TOp2 Add sx sr) : t)
        \end{haskell}

        \begin{haskell}[caption=Tracing array instantiation and array mapping, label=lst:trace_map, gobble=12]
            -- traceArrayLift takes the name of the array, the contents, and the current index
            traceArrayLift :: String -> [Float] -> Int -> Trace
            -- Empty lists get no trace
            traceArrayLift _ []     _ = []
            traceArrayLift s (x:xs) i = 
                -- Create the name for this item from the array's name and the current index
                let s' = s ++ `!' : show i
                -- Trace x as a single real number
                    tx = TLift (TReal s' x)
                -- Trace the rest of the array
                    txs = traceArrayLift s xs (i + 1)
                -- Return the combined trace
                in  tx : txs

            -- traceArrayMap takes the function to map, the name of the old array, the name of the new array, 
            -- the contents of the old array, and the current index
            traceArrayMap :: (TValue -> (TValue, Trace)) -> String -> String -> [Float]
                -> Int -> (TValue, Trace)
            traceArrayMap _ _  sn []     _ = (TArray sn [], [])
            
            traceArrayMap f so sn (x:xs) i =
                -- Get the current value from the array with the right name
                let current  = TReal (so ++ `!' : show i) x
                -- Get the result from the function application
                    (fv, ft) = f current
                -- Get the results from the rest of the array
                    (xsv, xst) = traceArrayMap f so sn xs (i + 1)
                -- To add to the TArray and to rename fv we use this case-of statement
                in  case (fv, xsv) of
                    (TReal s' v, TArray _ xsv') ->
                        -- Add this item to the new array
                        let vn = TArray sn (v : xsv')
                        -- Rename fv in the function trace to the correct name
                            ft' = rename s' (sn ++ `!' : show i) ft
                        -- Finally return the new array and the combined trace
                        in  (vn, ft' ++ xst)

            rename :: String -> String -> Trace -> Trace
        \end{haskell}

        \begin{haskell}[caption=Tracing array folding, label=lst:trace_fold, gobble=12]
            -- foldFunction makes a binary function out of two nested lambda functions
            foldFunction :: (TValue -> (TValue, Trace))
                -> (TValue -> TValue -> (TValue, Trace))
            foldFunction f x y = case f x of
                (TFunc g, tf) -> let (vg, tg) = g y in (vg, tf ++ tg)
                _             -> error ``Type mismatch in foldFunction''

            -- Traces all steps in a simple left-to-right fold
            traceArrayFold :: (TValue -> TValue -> (TValue, Trace)) -> TValue
                -> TValue -> Int -> (TValue, Trace)
            -- When the array is empty, return just the identity value and an empty trace
            traceArrayFold f z (TArray _  [])       _ = (z, [])

            traceArrayFold f z (TArray sa (vx:vxs)) i =
                    -- Create a current value
                let x          = TReal (sa ++ `!' : show i) vx
                    -- Do the folding step
                    (vf,  tf)  = f z x
                    -- Continue for the rest of the array
                    (vxs, txs) = traceArrayFold f vf (TArray sa vxs) (i + 1)
                    -- Combine the trace for the rest of the array with this step's trace
                in  (vxs, tf ++ txs)
        \end{haskell}

        While the concepts behind tracing away arrays are hopefully not too difficult to understand, it should be obvious from Listings \ref{lst:trace_map} and \ref{lst:trace_sum} that the implementation becomes more complex.
        Now while that is not really a problem, we should really note that the trace becomes messier as well.
        This is especially problematic if we actually want to read the trace to see what is going on: not impossible, but also not pleasant, especially with large arrays.
        So perhaps we are tempted to keep arrays in the trace instead, or perhaps we are interested in the trace of arrays specifically.

        Luckily for us, in large parts tracing while keeping arrays is fairly easy.
        This is because we can treat most operations like how we treated operations for real numbers.
        This has been done in Listing \ref{lst:trace_array2}, except for generate, map, and fold, where we replace the tracing patterns from Listing \ref{lst:trace_array}.

        \begin{haskell}[caption=Tracing whilst keeping arrays, label=lst:trace_array2, gobble=12]
            trace :: TEnvironment -> Expression -> (TValue, Trace)
            trace n (ELift v) =
                case v of
                    (VReal  v) -> $\ldots$
                    (VBool  v) -> $\ldots$
                    (VArray v) -> 
                        let s = getName
                        -- Literal lifting of arrays becomes real simple
                        in  (TArray s v, [(s, TLift (TArray s v))])

            trace n (EOp0 op) =
                case op of
                    (Iota r) ->
                        let s = getName
                            v = [0.0 .. (r - 1)]
                            -- Iota again becomes very similar to literal array lifting
                        in  (TArray s v, [s, TLift (TArray s v)])
            
            trace n (EOp1 op e1) =
                -- We trace e1 first, and create a name just in case
                let (v1, t1) = trace n e1
                    s = getName
                in  case (op, v1) of
                    (Idx i, TArray s1 v) =
                        let x  = v !! i
                            s' = s1 ++ `!' : show i
                        -- Now we trace arrays, indexing becomes more relevant to add to our trace,
                        -- as the individual item has not been defined before
                        in  (TReal s' x, (s', TOp1 op s1) : t1)
                    -- Sum becomes very simple, just apply it to the array
                    (Sum, TArray s1 v) = (TReal s (sum v), (s, TOp1 Sum s1) : t1)
        \end{haskell}

        In our current language, the main point of difficulty and interest is the generate, map, and fold operations.
        They take in a function, which is not a type we wish to keep in our trace, however they produce an array which we wish to keep in our trace.
        While we might be tempted to just discard the function component, we cannot do that because it provides the trace from the original array to the new array.
        Without that information our trace is no longer a functional (straight-line) program.

        The intuitive way to solve this, the naïve method, would be to attach an array of traces to the map operator, so they can be followed to derive the correct results.
        Similarly, we can do this for the generate and fold operations.
        To easily do this we extend our \texttt{Traced} ADT with a special map constructor (\texttt{TMap}), and a special fold constructor (\texttt{TFold}).
        We show this in Listings \ref{lst:trace_naive} and \ref{lst:trace_fold_naive}.
        We will also express our generate operation as a combination of the iota and map operations here, which saves us from writing a special case for generate.
        The traces in the \texttt{TMap} constructor correspond with the application of the function to be mapped to the individual item, for each item.
        The string references the array the map is performed on.
        Meanwhile, the \texttt{TFold} operator references the folding process as a single sub-trace, and also the name of the map it is executed on.

        \begin{haskell}[caption={Tracing generate and map while keeping arrays, naïvely}, label=lst:trace_naive, gobble=12]
            data Traced
                = $\ldots$
                | TMap  [Trace] String
                | TFold Trace   String String

            trace :: TEnvironment -> Expression -> (TValue, Trace)
            trace n (EOp1 op e1)    =
                -- We first trace e1, and generate a name
                let (v1, t1) = trace n e1
                    s = getName
                in  case (op, v1) of
                    $\ldots$
                    (Gen r, TFunc f) ->
                        let tg = (s, TLift (TArray s [0 .. (r - 1)]))
                            s' = getName
                            (vs, ts) = traceMapNaive f s s' [0 .. (r - 1)] 0
                        -- The trace becomes the iota followed by the map, explained below
                        in  (vs, (s, TMap ts sa) : tg : t1)
            
            trace n (EOp2 op e1 e2) =
                let (v1, t1) = trace n e1
                    (v2, t2) = trace n e2
                    s = getName
                in  case (op, v1, v2) of
                    $\ldots$
                    (Map, TFunc f, TArray sa va) ->
                        let (vs, ts) = traceMapNaive f sa s va 0
                        -- The trace becomes TMap, the collection of traces ts, on the old array v2 (with  
                        -- name sa)
                        in  (vs, [(s, TMap ts sa)])

            -- traceMapNaive takes in the function to be mapped, the name of the old array, the name of the 
            -- new array, the contents of the old array, and the current index
            traceMapNaive :: (TValue -> (TValue, Trace)) -> String -> String -> [Float]
                -> Int -> (TValue, [Trace])
            -- A map over an empty array returns the empty array and no traces
            traceMapNaive _ _  sn []     _ = (TArray sn [], [])

            traceMapNaive f so sn (x:xs) i =
                -- Create specific names for the old and new value
                let old = so ++ `!' : show i
                    new = sn ++ `!' : show i
                    -- Apply the function, getting the value for x and its trace
                    (xv, xt) = f (TReal old x)
                    -- Apply the function for the rest of the map
                    (xsv, xst) = traceMapNaive f so sn xs (i + 1)
                    -- We use a case-of statement to append xv to xsv and to rename xv in xt
                in  case (xv, xsv) of
                    (TReal s' v, TArray _ vs) ->
                        let xt' = rename s' new xt
                        in  (TArray sn (v : vs), xt' : xst)
        \end{haskell}

        \begin{haskell}[caption=Naive fold tracing, label=lst:trace_fold_naive, gobble=12]
            trace :: TEnvironment -> Expression -> (TValue, Trace)
            $\dots$
            trace n (EOp3 op e1 e2 e3) =
                -- Trace the expression to operate on
                let (v1, t1) = trace n e1
                    (v2, t2) = trace n e2
                    (v3, t3) = trace n e3
                in  case (v1, v2, v3) of
                    (TFunc f, TReal s2 _, TArray s3 _) -> 
                        -- We use the earlier fold tracing function
                        let (vf, tf) = traceArrayFold (foldFunction f) v2 v3
                        in  (vf, TFold tf s2 s3 : t1 ++ t2 ++ t3)
                    _                                  ->
                        error "Type mismatch in trace/EOp3"
        \end{haskell}

        Now, while the naïve way for maps is fine in functionality, it does again create some overhead (a trace for each item in the array) by splitting the trace into multiple smaller traces.
        And if the function is the same for every item in the array, we may find ourselves saving a lot of redundant data.
        Now, this may be necessary: at the time we map a function over an array, we do not know if it will act the same for every input.
        Perhaps there is some control flow in the function body that checks if a number is even, or a factor of three, or something else entirely.
        In such a case, having a trace for each item may be strictly necessary.
        However, it also highlights for which functions it may not be: functions without control flow or branching.
        After all, these functions are little straight-line programs, and should act the same no matter on what input they are applied (except for producing a different result, of course).
        Writing a function that checks if the body of a lambda abstraction contains branching is very simple for this language: currently the only expression term that can introduce branching is the if-then-else statement.
        Unfortunately, we cannot check that at the moment when we trace a map operator.
        This is because any function here would already have been abstracted to a \texttt{TFunc} value.
        So, we would need to check for branching when we are abstracting the function, and we also need a way to convey if a specific instance of \texttt{TFunc} contains branching or not.
        We write branch-checking into functions in Listing \ref{lst:branching}.
        For most terms we can just commute the branch checking to the arguments of that term, but there are a couple exceptions.
        If-then-else statements are the definition of branching in our language, so they return `true', and no branching can occur in literal instantiation (\texttt{ELift}) or nullary operators (\texttt{Op0}) (literal instantiation can also be rewritten as a nullary operator), so they always return `false'.
        Only for variable reference, which may return a value without actually providing a code to check, we need to see if the value is a function, and whether it has the branching flag set or not.
        This works because we set the branching flag when functions are defined using abstraction, and because functions may not be entered as literals.

        \begin{haskell}[caption=Checking for branches, label=lst:branching, gobble=12]
            data TValue
                = $\ldots$
                -- Add a branching flag to TFunc
                | TFunc Bool (TValue -> (TValue, Trace))

            branchCheck :: TEnvironment -> Expression -> Bool
            -- Encountering an if-else-statement means a encountering a branch
            branchCheck _ (EIf _ _ _) = True

            branchCheck n (EApply e1 e2) = branchCheck n e1 || branchCheck n e2
            branchCheck n (ELambda _ e1) = branchCheck n e1
            branchCheck n (ELet _ e1 e2) = branchCheck n e1 || branchCheck n e2
            -- ELift is always false, because lifting functions is not allowed
            branchCheck _ (ELift) = False
            branchCheck _ (EOp0 _) = False
            branchCheck n (EOp1 _ e1) = branchCheck n e1
            branchCheck n (EOp2 _ e1 e2) = branchCheck n e1 || branchCheck n e2
            branchCheck n (EOp3 _ e1 e2 e3) =
                branchCheck n e1 || branchCheck n e2 || branchCheck n e3
            
            -- If our variable contains a function we need to check what it has the branching flag set to
            branchCheck n (ERef s1) = case n ! s1 of
                (TFunc b _) -> b
                _           -> False
        \end{haskell}

        With our branch checking defined we still need to talk about how we actually apply that and make a trace for map that requires less information.
        The basic idea here is that we can essentially perform vectorization of our function on the array in our trace: we rewrite the trace such that the function is ``applied'' to the whole array, rather than its individual items.
        Now without support for this in our language, this basically amounts to syntactic sugar in our trace, however it will provide us with a much clearer trace.
        This has been done in Listing \ref{lst:vectorize}, where we again add a map operator to our \texttt{Traced} ADT.
        This is because we may need to use the naïve method if a function contains branching, and we cannot vectorize it.
        In Listing \ref{lst:vectorize} we still use \texttt{traceMapNaive} to actually map over our array.
        This is because we need to get the value of the array regardless, and our function value (\texttt{TFunc}) will return traces regardless if we need them or not.
        Then we can just take the first trace returned by the naïve map tracing, and rename all references to the first item of both the new and old arrays, to references of the whole old and new arrays respectively.
        For this end we define a function \texttt{deepRename} at the end of Listing \ref{lst:vectorize}.
        Like with the renaming function in Listing \ref{lst:trace_map}, the implementation of this function is not all that interesting: since all a \texttt{Trace} object is, is a list of tuples with a name that may need renaming and a \texttt{Traced} constructor referencing zero to two strings that may need renaming.
        All \texttt{deepRename} would do is go over these items and rename any occurrences it finds.

        \begin{haskell}[caption=Array mapping with trace vectorization, label=lst:vectorize, gobble=12]
            data Traced
                = $\ldots$
                -- We leave the naive TMap untouched
                | TMap  [Trace] String
                -- And add a new one for vectorized traces
                | TMapV Trace   String

            trace :: TEnvironment -> Expression -> (TValue, Trace)
            trace n (ELambda s1 e1) =
                -- We add branch checking when we handle abstraction
                let b = branchCheck e1
                    f = TFunc b ($\backslash$x -> trace (insert s x) e1)
                in  (f, [])

            trace n (EOp1 op e1) =
                let (v1, t1) = trace n e1
                    s = getName
                in  case (op, v1) of
                    $\ldots$
                    (Gen r, TFunc b f) ->
                        let tg = (s, TOp0 (Iota r))
                            s' = getName
                            (vs, ts) = traceMapNaive f s s' [0 .. (r - 1)] 0
                        in  if   b
                            then (vs, (s', TMap ts s) : tg : t1)
                            else let t' = vectorizeTrace s' s (head ts)
                                 in  (vs, (s, TMapV t' s) : tg : t1)

            trace n (EOp2 op e1 e2) =
                let (v1, t1) = trace n e1
                    (v2, t2) = trace n e2
                    s = getName
                in  case (op, v1, v2) of
                    $\ldots$
                    (Map, TFunc b f, TArray sa va) ->
                        -- We first get the result array (and all the traces) using the naive method
                        let (vs, ts) = traceMapNaive f sa s va 0
                        in  if   b
                            -- If the function contains branching, use the naive method
                            then (vs, (s, TMap ts sa) : t1 ++ t2)
                            -- Otherwise use the new method
                            else let t = vectorizeTrace sa s (head ts)
                                 in  (vs, (s, TMapV t sa) : t1 ++ t2)

            vectorizeTrace :: String -> String -> Trace -> Trace
            -- Rename the references to individual items to the whole array
            vectorizeTrace so sn t = deepRename iso so (deepRename isn sn t)
                -- The names for the individual items in this trace
                where iso = so ++ ``!0''
                      isn = sn ++ ``!0''

            deepRename :: String -> String -> Trace -> Trace
        \end{haskell}

        We can also be more efficient with fold, rather than doing a sequential left-to-right fold.
        Like vectorized maps, we can execute folds using data parallelism if the folding function is vectorizable.
        A data parallel fold is a little more in-depth than a vectorized mapping operation.
        Mainly because, at some point, fold requires some sequential steps.
        However, it is not too complicated: we segment the original array over a number of threads, and let those run sequentially.
        Then we gather those results in another array, and sequentially fold over that array to finish the fold.
        Of course, for this to work properly every time, the function used in the fold needs to be associative, so it does not matter we run the fold out of order.
        We implement this two-step data-parallel fold in Listings \ref{lst:trace_foldv} and \ref{lst:segmented}, where we also introduce a new constructor to the \texttt{Traced} data type, namely \texttt{FoldV}.
        We see in Listing \ref{lst:segmented} how we distribute the work over the number of threads available to us (represented by the \texttt{threads} variable).
        For each thread we still use the original function (that traces away arrays), because it performs the (partial) fold, and produces the correct trace.
        Then, when we have no threads left, we combine our results and trace the fold over that as well.
        It should be clear that the code in Listings \ref{lst:trace_foldv} and \ref{lst:segmented} do not run the code using parallelism.
        Instead, they are just a sequential implementation meant to show off how we could build a parallel variant.

        \begin{haskell}[caption=Data parallel fold tracing, label=lst:trace_foldv, gobble=12]
            data Traced
                = $\dots$
                -- We leave the original TFold untouched
                | TFold Trace String String
                -- And add a new one for vectorized folds
                | TFold Trace String Trace  String String
                -- And we add a new helper constructor used for foldv
                | TJoin [String]

            trace :: TEnvironment -> Expression -> (TValue, Trace)
            $\dots$
            trace n (EOp3 op e1 e2 e3) = 
                let (v1, t1) = trace n e1
                    (v2, t2) = trace n e2
                    (v3, t3) = trace n e3
                in  case (v1, v2, v3) of
                    (TFunc b f, TReal s2 v2', TArray s3 _) ->
                        if   b  
                             -- If branching is present, use the old method
                        then let (vf, tf) = traceArrayFold f v2 v3
                             in  (vf, TFold tf s2 s3 : t1 ++ t2 ++ t3)
                             -- If not, we will use the segmented fold,
                             -- which returns the final value, the traces for the first step,
                             -- the traces for the second step, and the name of the join variable
                        else let (vf, tf1, js, tf2) =
                                    segmentedFold (foldFunction f) v3 s2 v2'
                             in (vf, TFoldV tf1 js tf2 s2 s3 : t1 ++ t2 ++ t3)

            segmentedFold :: (TValue -> TValue -> (TValue, Trace))
                -> TValue -> String -> [Float]
                -> (TValue, [Trace], String, Trace)
            -- See Listing !*\ref{lst:segmented}*!
        \end{haskell}

        \begin{haskell}[caption=Segmented fold, label=lst:segmented, gobble=12]
            segmentedFold :: (TValue -> TValue -> (TValue, Trace))
                -> TValue -> String -> [Float]
                -> (TValue, [Trace], String, Trace)
            segmentedFold f z sa xs =
                controller threads [] xs [] []
                where
                    controller :: Int -> [Trace] -> [Float] -> [Float]
                        -> [String] -> (TValue, [Trace], String, Trace)
                    -- When all threads are done, combine them in to one
                    controller 0 ts _   rs srs =
                        let s  = getName
                            z' = TReal (s ++ ``!0'') (head rs)
                            a' = TArray s (tail rs)
                            (vc, tc) = traceArrayFold f z' a' 1
                            js = getName
                            tc' = (js, TJoin srs) : tc
                        in  (vc, ts, js, tc')

                    controller t ts xs' rs srs =
                        -- If we can evenly distribute the rest of the array over the next threads
                        | mod (length xs' + 1) t == 0 =
                            if   length xs' == length xs
                            then let size = length xs' `div` threads
                                     sarr = take (size - 1) xs'
                                     (vf, tf) = traceArrayFold f z (TArray sa sarr) 0
                                 in  case vf of
                                     TReal sr r -> controller (t - 1) (tf : ts)
                                        (drop (size - 1) xs') (r : rs) (sr: srs)
                            else let size = length xs' `div` threads
                                     sarr = take size xs'
                                     l    = length xs - length xs'
                                     z'   = TReal (sa ++ `!' : show l) (head sarr)
                                     (vf, tf) = traceArrayFold f z' (TArray sa (tail sarr)) l
                                 in  case vf of
                                     TReal sr r -> controller (t - 1) (tf : ts) 
                                        (drop size xs') (r : rs) (sr: srs)
                        | otherwise               =
                            if   length xs' == length xs
                            then let size = length xs' `div` threads
                                     sarr = take size xs'
                                     (vf, tf) = traceArrayFold f z (TArray sa sarr) 0
                                 in  case vf of
                                     TReal sr r -> controller (t - 1) (tf : ts)
                                        (drop size xs') (r : rs) (sr: srs)
                            else let size = length xs' `div` threads + 1
                                     sarr = take size xs'
                                     l    = length xs - length xs'
                                     z'   = TReal (sa ++ `!' : show l) (head sarr)
                                     (vf, tf) = traceArrayFold f z' (TArray sa (tail sarr)) l
                                 in  case vf of
                                     TReal sr r -> controller (t - 1) (tf : ts)
                                        (drop size xs') (r : rs) (sr: srs)
        \end{haskell}

        What is important to take away from the shenanigans with the generate, map, and fold operators is that, whilst our definitions and correctness assertions from Sections \ref{sec:tracing} and \ref{sec:correctness} gave us some guidance, there is ultimately no single way to trace everything.
        The most important factor here is to keep reminding ourselves of the information we wish to keep in the trace.
        Not only the value types, but we also need the information needed to actually run the trace as a program.
        Keeping this in mind, it becomes much more obvious how to trace these operations.
