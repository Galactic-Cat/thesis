\section{Tracing}
    In the broadest terms, when we trace a program, we track the most basic steps the program takes provided some input.
    This is relevant for many applications in Computer Science.
    Certain automatic differentiation (AD) implement the forward-pass as effectively tracing, and then perform the reverse pass on the trace\cn.
    Tracing is also used to speed up program execution by making assumptions on the program's execution path from the trace\cn.
    \cc{Another example? Rule of threes!}

    However, despite its ambivalence, tracing is rarely properly defined, or defined only for a specific use case.
    So, in this section we will set out to create a more general definition of tracing.
    
    To start, it will help us along to set clear expectations for what we expect a tracing function to do.
    In the simplest terms, we expect a tracing program to take an input program with a set of inputs, and output a ``trace''.
    This output trace is generally defined as a set of operations the input program performed on the inputs.
    A term often used for an output trace is a ``single-line program''\cn: a program without control flow.
    Clearing control flow like if-then-else statements is only natural: after all, provided some input the program will only walk down one variation of this branching path.

    Furthermore, it is also generally accepted that the trace consists of a subset of the syntax of the input program.
    Because we're generally more interested in what happens to the data in our program, we can ``trace away'' functions and data structures.
    More precisely, if our input program has the types as defined in Equation \ref{eq:typebase}, where we have sum-types as $\tau+\sigma$, product types as $\tau\times\sigma$, functions as $\tau\to\sigma$, literal real numbers, and literal Booleans.

    \begin{equation}
        \label{eq:typebase}
        \tau,\sigma\coloneqq\tau+\sigma\|\tau\times\sigma\|\tau\to\sigma\|\mathbb{R}\|\mathbb{B}
    \end{equation}

    By choosing a subset of the types in our program, we can indicate which data structures should be traced away.
    A common option is to keep only ``grounded types'', where we defined a grounded type as a type that isn't constructed of other types.
    Looking at our example in Equation \ref{eq:typebase}, a trace keeping only these grounded types would keep only the real numbers and the Booleans as they are not built of other types.
    % It should also be noted that these ``grounded types'' are impossible to trace away, so we don't have much of a choice on those.
    Another common option is to keep only continuous types, tracing away all ungrounded and discrete types.
    Do that on our type set in Equation \ref{eq:typebase} would leave us with only the real numbers.
    This is under the assumption that the discrete types aren't actually used as data we're interested in tracing of course, but since tracing will remove all control flow from the program, keeping Booleans and operations on Booleans intact may be meaningless. 

    The main take-away here is that there is some freedom of choice in what to trace away.
    What parts we keep and what parts we trace away is very dependent on what information we want to keep in our trace.
    Which in turn is dependent on what our exact goal is for the tracing in the first place.
    
    We can also choose to keep some of our ungrounded types, but then we run into a problem.
    Say we keep only functions ($\tau\to\sigma$) and real numbers, but our input program contains a function with type $\tau\to(\sigma_1+\sigma_2)$.
    This typing is valid in our input program, but no longer valid in our trace, so we find ourselves in a bind.
    It will be impossible to trace away the sum-type in the output of the function without tracing away the function itself.
    \cc{Why exactly?}
    Of course we could define a subset $\tau',\sigma'\coloneqq\mathbb{R}$ and then redefine (or add a definition for) our function so that it becomes $\sigma'\to\tau'$ making it safe to trace.
    This then underlines the rule at work here: we can only keep types that do cannot be constructed of types that are traced away.
    This is why the grounded types are a natural set of types to keep, as they are never constructed from other types.

    It seems that our tracing definition comes down to a function that takes in a program and an input to that program, and outputs the steps taken by the program run on the input.
    Where the input program takes uses some set of types, of which only a subset is kept in the trace, where the types in this subset may not be constructed using types from outside of the subset.

    What now remains is a concrete definition of the output of the tracing program.
    We have already stated that it should somehow contain the steps done in by the input program.
    The steps we wish to record are generally basic operations like arithmetic operations.
    But other operations, such as operations on arrays, can also be added depending on the ultimate goal of the tracing.
    More importantly, as we expect our trace to be akin to a single-line program, we may consider our trace as a series of let-bindings, akin to A-normal form\cn.
    
    Finally, we can quickly check if our trace is correct by executing the trace and checking whether the result is the same as in the input program.
    We can also check the correctness of our tracing program by running it with a trace as its input program.
    Tracing a trace should return the trace itself, because if it returned some more minimal trace, we know that the first trace wasn't properly finished.

    \subsection{Tracing steps}
        We will now define some of the basic tracing steps for some arbitrary language as logical transformation rules.
        To do this we first define a very basic language on which we will operate.
        We will start by only defining the most basic types for our variables: $\tau,\sigma\coloneqq\mathbb{R}\|\sigma\to\tau$.
        This allows us to define a simple lambda calculus on real numbers:
        % \[
        %     \Gamma\vdash c:\tau\quad\text{(Constant)}
        % \]

        \begin{prooftree}
            \AxiomC{}
            \RightLabel{(Constant)}
            \UnaryInfC{$\Gamma\vdash c:\tau$}
        \end{prooftree}

        \begin{prooftree}
            \AxiomC{$(x:\tau)\in\Gamma$}
            \RightLabel{(Variable)}
            \UnaryInfC{$\Gamma\vdash x:\tau$}
        \end{prooftree}

        \begin{prooftree}
            \AxiomC{$\Gamma\cup\{x:\tau\}\vdash e:\sigma$}
            \RightLabel{(Abstraction)}
            \UnaryInfC{$\Gamma\vdash(\lambda(x:\tau).e):\tau\to\sigma$}
        \end{prooftree}

        \begin{prooftree}
            \AxiomC{$\Gamma\vdash e_1:\tau\to\sigma$}
            \AxiomC{$\Gamma\vdash e_2:\tau$}
            \RightLabel{(Application)}
            \BinaryInfC{$\Gamma\vdash(e_1\ e_2):\sigma$}
        \end{prooftree}

        Tracing through this lambda calculus is then fairly straightforward.
        We will define $\tau_T$ and $\sigma_T$ as type indicators for the types of the trace, such that $\tau_T,\sigma_T\subseteq\tau,\sigma$.
        % Also, we will define $\Gamma_T$ as the tracing language.

        \begin{prooftree}
            \AxiomC{$\Gamma\vdash e:\tau$}
            \RightLabel{(Tracing Introduction)}
            \UnaryInfC{$\Gamma\vdash\text{trace}(e):\tau_T$}
        \end{prooftree}

        \begin{prooftree}
            \AxiomC{$\Gamma\vdash\text{trace}(c:\tau_T)$}
            \RightLabel{(Constant tracing)}
            \UnaryInfC{$\Gamma\vdash c:\tau_T$}
        \end{prooftree}

        \begin{prooftree}
            \AxiomC{$(x:\tau_T)\in\Gamma$}
            \AxiomC{$\text{trace}(x)$}
            \RightLabel{(Variable tracing)}
            \BinaryInfC{$\Gamma\vdash x:\tau_T$}
        \end{prooftree}

        \begin{prooftree}
            \AxiomC{$\Gamma\vdash\text{trace}(\lambda(x:\tau).e:\tau\to\sigma)$}
            \RightLabel{(Abstraction tracing)}
            \UnaryInfC{$\Gamma\vdash\lambda(x:\tau_T).\text{trace}(e):\tau_T\to\sigma_T$}
        \end{prooftree}

        \begin{prooftree}
            \AxiomC{$\Gamma\vdash e_1:\tau\to\sigma$}
            \AxiomC{$\Gamma\vdash e_2:\tau$}
            \AxiomC{$\Gamma\vdash\text{trace}(e_1\ e_2)$}
            \RightLabel{(Application tracing)}
            \TrinaryInfC{$\Gamma\vdash((\text{trace}(e_1):\tau_T\to\sigma_T)\ (\text{trace}(e_2):\tau_T)):\sigma_T$}
        \end{prooftree}

        We can then extend this with the basic operations we wish to preserve through our trace.
        We will denote these operations as $op(e_1,\dots,e_n)$ with $n$ arguments, for all functions $op:(\mathbb{R}\cup\mathbb{B})_n\to\mathbb{R}\cup\mathbb{B}$.
        \cc{This type signature needs fixin'.}
        As long as we want to preserve these operations in our trace they are generally homomorphic.

        \begin{prooftree}
            \AxiomC{$\Gamma\vdash e_1:\tau',\dots,e_n:\tau'$}
            \AxiomC{$\tau'\in\{\mathbb{B},\mathbb{R}\}$}
            \AxiomC{$\sigma'\in\{\mathbb{B},\mathbb{R}\}$}
            \RightLabel{(Basic operations)}
            \TrinaryInfC{$\Gamma\vdash op(e_1,\dots,e_n):\sigma'$}
        \end{prooftree}

        \begin{prooftree}
            \AxiomC{$\Gamma_T\vdash\text{trace}(op(e_1,\dots,e_n))$}
            \RightLabel{(Trace on basic operations)}
            \UnaryInfC{$\Gamma_T\vdash op(\text{trace}(e_1),\dots,\text{trace}(e_n))$}
        \end{prooftree}